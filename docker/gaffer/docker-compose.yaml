version: "3.7"

services:

  zookeeper:
    image: zookeeper:3.5.6
    container_name: zookeeper
    hostname: zookeeper

  hdfs-namenode:
    image: gchq/hdfs:${HADOOP_VERSION}
    build:
      context: ../hdfs/
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    command: namenode
    container_name: hdfs-namenode
    hostname: hdfs-namenode
    environment:
    - HADOOP_CONF_DIR=${HADOOP_CONF_DIR}
    ports:
    - 9870:9870
    volumes:
    - ../hdfs/conf:${HADOOP_CONF_DIR}:ro
    - /var/log/hadoop
    - /data1
    - /data2

  hdfs-datanode:
    depends_on:
    - hdfs-namenode
    image: gchq/hdfs:${HADOOP_VERSION}
    build:
      context: ../hdfs/
      args:
        HADOOP_VERSION: ${HADOOP_VERSION}
    command: datanode
    container_name: hdfs-datanode
    hostname: hdfs-datanode
    environment:
    - HADOOP_CONF_DIR=${HADOOP_CONF_DIR}
    volumes:
    - ../hdfs/conf:${HADOOP_CONF_DIR}:ro
    - /var/log/hadoop
    - /data1
    - /data2

  accumulo-master:
    depends_on:
    - hdfs-namenode
    - hdfs-datanode
    - zookeeper
    image: gchq/gaffer:${GAFFER_VERSION}
    build:
      context: .
      args:
        GAFFER_VERSION: ${GAFFER_VERSION}
        BASE_IMAGE_NAME: gchq/accumulo
        BASE_IMAGE_TAG: 1.9.3
    command: master
    restart: on-failure
    container_name: accumulo-master
    hostname: accumulo-master
    environment:
    - ACCUMULO_CONF_DIR=${ACCUMULO_CONF_DIR}
    # There doesn't seem to be an easy way (with docker-compose) to init our
    # HDFS instance with the right permissions so that Accumulo can create the
    # file structure it needs. Using the following workaround to allow
    # accumulo to "auth" with HDFS as the super user so that it can:
    - HADOOP_USER_NAME=hadoop
    volumes:
    - ../accumulo/conf:${ACCUMULO_CONF_DIR}:ro
    - /var/log/accumulo

  accumulo-tserver:
    depends_on:
    - accumulo-master
    image: gchq/gaffer:${GAFFER_VERSION}
    build:
      context: .
      args:
        GAFFER_VERSION: ${GAFFER_VERSION}
        BASE_IMAGE_NAME: gchq/accumulo
        BASE_IMAGE_TAG: 1.9.3
    command: tserver
    restart: on-failure
    container_name: accumulo-tserver
    hostname: accumulo-tserver
    environment:
    - ACCUMULO_CONF_DIR=${ACCUMULO_CONF_DIR}
    # There doesn't seem to be an easy way (with docker-compose) to init our
    # HDFS instance with the right permissions so that Accumulo can create the
    # file structure it needs. Using the following workaround to allow
    # accumulo to "auth" with HDFS as the super user so that it can:
    - HADOOP_USER_NAME=hadoop
    volumes:
    - ../accumulo/conf:${ACCUMULO_CONF_DIR}:ro
    - /var/log/accumulo

  accumulo-monitor:
    depends_on:
    - accumulo-master
    image: gchq/gaffer:${GAFFER_VERSION}
    build:
      context: .
      args:
        GAFFER_VERSION: ${GAFFER_VERSION}
        BASE_IMAGE_NAME: gchq/accumulo
        BASE_IMAGE_TAG: 1.9.3
    command: monitor
    restart: on-failure
    container_name: accumulo-monitor
    hostname: accumulo-monitor
    environment:
    - ACCUMULO_CONF_DIR=${ACCUMULO_CONF_DIR}
    # There doesn't seem to be an easy way (with docker-compose) to init our
    # HDFS instance with the right permissions so that Accumulo can create the
    # file structure it needs. Using the following workaround to allow
    # accumulo to "auth" with HDFS as the super user so that it can:
    - HADOOP_USER_NAME=hadoop
    ports:
    - 9995:9995
    volumes:
    - ../accumulo/conf:${ACCUMULO_CONF_DIR}:ro
    - /var/log/accumulo

  accumulo-gc:
    depends_on:
    - accumulo-master
    image: gchq/gaffer:${GAFFER_VERSION}
    build:
      context: .
      args:
        GAFFER_VERSION: ${GAFFER_VERSION}
        BASE_IMAGE_NAME: gchq/accumulo
        BASE_IMAGE_TAG: 1.9.3
    command: gc
    restart: on-failure
    container_name: accumulo-gc
    hostname: accumulo-gc
    environment:
    - ACCUMULO_CONF_DIR=${ACCUMULO_CONF_DIR}
    # There doesn't seem to be an easy way (with docker-compose) to init our
    # HDFS instance with the right permissions so that Accumulo can create the
    # file structure it needs. Using the following workaround to allow
    # accumulo to "auth" with HDFS as the super user so that it can:
    - HADOOP_USER_NAME=hadoop
    volumes:
    - ../accumulo/conf:${ACCUMULO_CONF_DIR}:ro
    - /var/log/accumulo
